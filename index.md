## BlackboxNLP 2020

Neural networks have rapidly become a central component in NLP systems in
the last few years. The improvement in accuracy and performance brought by
the introduction of neural networks has typically come at the cost of our
understanding of the system: How do we assess what the representations and
computations are that the network learns? The goal of this workshop is to
bring together people who are attempting to peek inside the neural network
black box, taking inspiration from machine learning, psychology,
linguistics, and neuroscience. The topics of the workshop will include, but
are not limited to:

- Applying analysis techniques from neuroscience to analyze
high-dimensional vector representations (such as Haxby et al., 2001;
Kriegeskorte, 2008) in artificial neural networks;
- Analyzing the network's response to strategically chosen inputs in order
to infer the linguistic generalizations that the network has acquired
(e.g., Linzen et al., 2016; Loula et al., 2018);
- Examining the performance of the network on simplified or formal
languages (e.g., Hupkes et al., 2018; Lake et al., 2018);
- Proposing modifications to neural network architectures that can make
them more interpretable (e.g., Palanki et al., 2017);
- Scaling up neural network analysis techniques developed in the
connectionist literature in the 1990s (Elman, 1991);
- Testing whether interpretable information can be decoded from
intermediate representations (e.g., Adi et al.,  2017; Chrupala et al.,
2017; Hupkes et al., 2017);
- Translating insights on neural networks interpretation from the vision
domain (e.g., Zeiler & Fergus, 2014) to language;
- Explaining model predictions (e.g., Lei et al., 2016; Alvarez-Melis &
Jaakkola, 2017): What are ways to explain specific decisions made by neural
networks?
- Adversarial examples in NLP (e.g., Ebrahimi et al., 2018; Belinkov &
Bisk, 2018): How to generate them and how to evaluate their quality?
- Open-source tools for analyzing neural networks in NLP (e.g., Strobelt et
al., 2018; Rikters, 2018).
- Evaluation of analysis results: How do we know that the analysis is
valid?

BlackboxNLP 2020 is the third BlackboxNLP workshop. 
The programme and proceedings of the previous editions, which were held at EMNLP 2018 and ACL 2019, can be found [here](https://blackboxnlp.github.io/2018/) and [here](https://blackboxnlp.github.io/2019/).

## Important dates

TBA

## Workshop program 

TBA

## Invited speakers

TBA

## Submission

TBA

## Organizers

### Grzegorz Chrupała
Grzegorz Chrupała (g.chrupala@uvt.nl) is an Assistant Professor at the Department of Cognitive Science and Artificial Intelligence at Tilburg University. His research focuses on computational models of language learning from multimodal signals such as speech and vision and on the analysis and interpretability of representations emerging in
multilayer neural networks. His work has appeared in venues such as *Computational Linguistics*, ACL, EMNLP and CoNLL. He has served as area chair for ACL, EMNLP and CoNLL and he co-organized the first edition of BlackboxNLP.

### Yonatan Belinkov
Yonatan Belinkov (belinkov@seas.harvard.edu) is a Postdoctoral Fellow at the Harvard School of Engineering and Applied Sciences (SEAS) and the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). 
His recent research focuses on representations of language in neural network models, with applications in machine translation and speech recognition. 
His research has been published at ACL, EMNLP, TACL, ICLR, and NeurIPS. 
His PhD dissertation at MIT analyzed internal language representations in deep learning models. 

### Dieuwke Hupkes
Dieuwke Hupkes (d.hupkes@uva.nl) is a PhD student at the University of Amsterdam.
The main focus of her research is understanding how recurrent neural networks can understand and learn the structures that occur in natural language.
Developing methods to interpret and interact with neural networks has therefore been an important area of focus in her research.
She authored 5 articles directly relevant to the workshop, one of them published in a top AI journal (Journal of Artificial Intelligence), and she is co-organizing a workshop on compositionality, neural networks, and the brain to be held at the Lorentz Center in the summer of 2019.

## Program committee

 - 	Samira Abnar 
 - 	Željko Agić 
 - 	Afra Alishahi 
 - 	Antonios Anastasopoulos 
 - 	Niranjan Balasubramanian 
 - 	Joost Bastings 
 - 	Lisa Beinborn 
 - 	Laurent Besacier 
 - 	Or Biran 
 - 	Samuel R. Bowman 
 - 	Stergios Chatzikyriakidis 
 - 	Miryam de Lhoneux 
 - 	Ewan Dunbar 
 - 	Jacob Eisenstein 
 - 	Allyson Ettinger 
 - 	Antske Fokkens 
 - 	Robert Frank 
 - 	Richard Futrell 
 - 	Sharon Goldwater 
 - 	Kristina Gulordava 
 - 	David Harwath 
 - 	Germán Kruszewski 
 - 	Yair Lakretz 
 - 	Shalom Lappin 
 - 	Jindřich Libovický 
 - 	Nelson F. Liu 
 - 	Pranava Madhyastha 
 - 	David Mareček 
 - 	Paola Merlo 
 - 	Raymond Mooney 
 - 	Sebastian Padó 
 - 	Yves Peirsman 
 - 	Adam Poliak 
 - 	Rudolf Rosa 
 - 	Carolyn Rose 
 - 	Hassan Sajjad 
 - 	Wojciech Samek 
 - 	Naomi Saphra 
 - 	Rico Sennrich 
 - 	Pia Sommerauer 
 - 	György Szaszák 
 - 	Francesca Toni 
 - 	Adina Williams 
 - 	Roberto Zamparelli 
 - 	Fabio Massimo Zanzotto 
 - 	Willem Zuidema 

## Anti-Harassment Policy
BlackboxNLP 2019 adheres to the [ACL Anti-Harassment Policy](https://www.aclweb.org/adminwiki/sphp?title=Anti-Harassment_Policy).
